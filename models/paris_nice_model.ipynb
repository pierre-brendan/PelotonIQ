{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paris_nice_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPG/dSZwWUbWCp1xYbnOaM9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pierre-brendan/PelotonIQ/blob/master/models/paris_nice_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBT1R8ObJoSU",
        "colab_type": "text"
      },
      "source": [
        "# First attempt at a model to predict the winner of Paris - Nice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSXKvTvZJjO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount drive to get cyclist data\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tZ6OqLLJysB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All this code is from the Kmeans clustering code\n",
        "\n",
        "# load modules\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# load the rider data\n",
        "cycling_data = pd.read_csv('/content/drive/My Drive/cycling_data/rider_data.csv')\n",
        "cycling_data = cycling_data[cycling_data['Rider'] != 'Bjorg Lambrecht ']\n",
        "cycling_data = cycling_data[cycling_data['Rider'] != 'Robbert de Greef ']\n",
        "\n",
        "# Load the GC data\n",
        "gc_winners = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/gc_winners_consolidated.csv')\n",
        "gc_winners.rename(columns = {'Cyclist':'Rider'}, inplace = True)\n",
        "\n",
        "# Merge the GC winners to the rider data set\n",
        "cycling_data = pd.merge(cycling_data, gc_winners, how='left', on='Rider')\n",
        "\n",
        "# Load in the Monuments data\n",
        "san_remo = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/san_remo.csv')\n",
        "san_remo = san_remo['san_remo_win'].groupby(san_remo['Rider']).sum()\n",
        "roubaix = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/roubaix.csv')\n",
        "roubaix = roubaix['roubaix_win'].groupby(roubaix['Rider']).sum()\n",
        "flanders = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/flanders.csv')\n",
        "flanders = flanders['flanders_win'].groupby(flanders['Rider']).sum()\n",
        "lombardia = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/lombardia.csv')\n",
        "lombardia = lombardia['lombardia_win'].groupby(lombardia['Rider']).sum()\n",
        "liege = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/liege.csv')\n",
        "liege = liege['lbl_win'].groupby(liege['Rider']).sum()\n",
        "strade = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/strade.csv')\n",
        "strade['strade_win'] = 1\n",
        "strade = strade['strade_win'].groupby(strade['Rider']).sum()\n",
        "suisse = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/suisse.csv')\n",
        "suisse['suisse_win'] = 1\n",
        "suisse = suisse['suisse_win'].groupby(suisse['Rider']).sum()\n",
        "romandie = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/romandie.csv')\n",
        "romandie['romandie_win'] = 1\n",
        "romandie = romandie['romandie_win'].groupby(romandie['Rider']).sum()\n",
        "paris_nice = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/paris_nice.csv')\n",
        "paris_nice['paris_nice_win'] = 1\n",
        "paris_nice = paris_nice['paris_nice_win'].groupby(paris_nice['Rider']).sum()\n",
        "gent = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/gent.csv')\n",
        "gent['gent_win'] = 1\n",
        "gent = gent['gent_win'].groupby(gent['Rider']).sum()\n",
        "fleche = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/fleche.csv')\n",
        "fleche['fleche_win'] = 1\n",
        "fleche = fleche['fleche_win'].groupby(fleche['Rider']).sum()\n",
        "e3_binckbank = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/e3_binckbank.csv')\n",
        "e3_binckbank['e3_binckbank_win'] = 1\n",
        "e3_binckbank = e3_binckbank['e3_binckbank_win'].groupby(e3_binckbank['Rider']).sum()\n",
        "dauphine = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/dauphine.csv')\n",
        "dauphine['dauphine_win'] = 1\n",
        "dauphine = dauphine['dauphine_win'].groupby(dauphine['Rider']).sum()\n",
        "amstel = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/amstel.csv')\n",
        "amstel['amstel_win'] = 1\n",
        "amstel = amstel['amstel_win'].groupby(amstel['Rider']).sum()\n",
        "\n",
        "\n",
        "# Merge the Monuments winners to the rider data set\n",
        "cycling_data = pd.merge(cycling_data, san_remo, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, flanders, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, liege, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, lombardia, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, roubaix, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, strade, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, suisse, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, fleche, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, gent, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, paris_nice, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, e3_binckbank, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, amstel, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, dauphine, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, romandie, how='left', on='Rider')\n",
        "\n",
        "# Replace NaN with 0's\n",
        "cycling_data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop country variable\n",
        "cycling_data = cycling_data.drop(['Country', 'crawl_date'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNIWRKzCKPUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cycling_data.describe()\n",
        "# Okay, let's make a column for winners of Paris-Nice type races\n",
        "# Currently I'm thinking Paris - Nice, Tour de Suisse and Dauphine (Tierrento is not in the data set currently)\n",
        "cycling_data['Paris_Nice_etc'] = cycling_data['paris_nice_win'] + cycling_data['dauphine_win'] + cycling_data['suisse_win']\n",
        "\n",
        "# Will need to drop those 3 columns now\n",
        "cycling_data = cycling_data.drop(['paris_nice_win', 'dauphine_win', 'suisse_win'], axis = 1)\n",
        "\n",
        "# Split the data sets\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set = train_test_split(cycling_data, test_size = 0.1, \n",
        "                                       random_state = 42)\n",
        "# first let's make a fresh copy of our data and drop what we are trying\n",
        "# to predict so it doesn't have any transmations applied to it\n",
        "psg = train_set.drop('Paris_Nice_etc', axis=1)\n",
        "psg_labels = train_set['Paris_Nice_etc'].copy()\n",
        "psg_rider = train_set['Rider'].copy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOcvD8lLKL4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Also from KMeans code\n",
        "# This would be the best approach to removing special characters\n",
        "#dictionary = {'ž':'z', 'č':'c', 'ü':'u', 'á':'a', 'é':'e', 'ö':'o', 'ó':'o', 'ç':'c',\n",
        "#              'ń':'ń', 'í':'i', 'è':'e'}\n",
        "#cycling_data.replace(dictionary, regex=True, inplace=True)\n",
        "\n",
        "#d = psg.drop(['Rider'], axis=1) #, 'Team'\n",
        "\n",
        "# let's normalize the data\n",
        "psg['GC'] = preprocessing.scale(psg['GC'])\n",
        "psg['Sprint'] = preprocessing.scale(psg['Sprint'])\n",
        "psg['TT'] = preprocessing.scale(psg['TT'])\n",
        "psg['Climber'] = preprocessing.scale(psg['Climber'])\n",
        "psg['Classic'] = preprocessing.scale(psg['Classic'])\n",
        "psg['Age'] = preprocessing.scale(psg['Age'])\n",
        "psg['Giro'] = preprocessing.scale(psg['Giro'])\n",
        "psg['Vuelta'] = preprocessing.scale(psg['Vuelta'])\n",
        "psg['Tour'] = preprocessing.scale(psg['Tour'])\n",
        "psg['Total'] = preprocessing.scale(psg['Total'])\n",
        "psg['san_remo_win'] = preprocessing.scale(psg['san_remo_win'])\n",
        "psg['lombardia_win'] = preprocessing.scale(psg['lombardia_win'])\n",
        "psg['flanders_win'] = preprocessing.scale(psg['flanders_win'])\n",
        "psg['lbl_win'] = preprocessing.scale(psg['lbl_win'])\n",
        "psg['roubaix_win'] = preprocessing.scale(psg['roubaix_win'])\n",
        "psg['strade_win'] = preprocessing.scale(psg['strade_win'])\n",
        "#psg['suisse_win'] = preprocessing.scale(psg['suisse_win'])\n",
        "psg['fleche_win'] = preprocessing.scale(psg['fleche_win'])\n",
        "psg['gent_win'] = preprocessing.scale(psg['gent_win'])\n",
        "#psg['Paris_Nice_etc'] = preprocessing.scale(psg['Paris_Nice_etc'])\n",
        "psg['e3_binckbank_win'] = preprocessing.scale(psg['e3_binckbank_win'])\n",
        "psg['amstel_win'] = preprocessing.scale(psg['amstel_win'])\n",
        "#psg['dauphine_win'] = preprocessing.scale(psg['dauphine_win'])\n",
        "psg['romandie_win'] = preprocessing.scale(psg['romandie_win'])\n",
        "\n",
        "# Algorithims prefer working with numbers generally, so let's convert the team\n",
        "# proximity columns to numeric values\n",
        "psg['Team'] = psg['Team'].astype(str)\n",
        "housing_cat = psg[['Team']]\n",
        "# Problem is if we use numeric examples for these variables algorithims\n",
        "# will think they are near eachother. Instead we should make some one-hot\n",
        "# encodings otherwise known as dummy variables for each category as it's own\n",
        "# column\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "#ordinal_encoder = OrdinalEncoder()\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "#cat_encoder = OrdinalEncoder()\n",
        "#psg_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "#cat_attribs = ['Team']\n",
        "\n",
        "#full_pipeline = ColumnTransformer([\n",
        "#      ('cat', OneHotEncoder(), cat_attribs),\n",
        "#])\n",
        "\n",
        "#psg_prepared = full_pipeline.fit_transform(psg) # applying this to pandas dataframe called housing\n",
        "\n",
        "# not a fan of the approach above, changing it in the section below\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvBce0d5TC89",
        "colab_type": "code",
        "outputId": "aefec68b-55f0-4660-ecfe-eda91c0fdb1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "source": [
        "# use pd.concat to join the new columns with your original dataframe\n",
        "psg = pd.concat([psg,pd.get_dummies(psg['Team'], prefix='Team')],axis=1)\n",
        "\n",
        "# now drop the original 'country' column (you don't need it anymore)\n",
        "psg.drop(['Team'],axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rider</th>\n",
              "      <th>GC</th>\n",
              "      <th>TT</th>\n",
              "      <th>Sprint</th>\n",
              "      <th>Climber</th>\n",
              "      <th>Classic</th>\n",
              "      <th>Age</th>\n",
              "      <th>Giro</th>\n",
              "      <th>Tour</th>\n",
              "      <th>Vuelta</th>\n",
              "      <th>Total</th>\n",
              "      <th>san_remo_win</th>\n",
              "      <th>flanders_win</th>\n",
              "      <th>lbl_win</th>\n",
              "      <th>lombardia_win</th>\n",
              "      <th>roubaix_win</th>\n",
              "      <th>strade_win</th>\n",
              "      <th>fleche_win</th>\n",
              "      <th>gent_win</th>\n",
              "      <th>e3_binckbank_win</th>\n",
              "      <th>amstel_win</th>\n",
              "      <th>romandie_win</th>\n",
              "      <th>Team_ Israel Cycling Academy</th>\n",
              "      <th>Team_0</th>\n",
              "      <th>Team_7 Eleven Cliqq - air21 by Roadbike Philippines</th>\n",
              "      <th>Team_AG2R La Mondiale</th>\n",
              "      <th>Team_Adria Mobil</th>\n",
              "      <th>Team_Aisan Racing Team</th>\n",
              "      <th>Team_Alpecin-Fenix</th>\n",
              "      <th>Team_Amore &amp; Vita - Prodir</th>\n",
              "      <th>Team_Androni Giocattoli - Sidermec</th>\n",
              "      <th>Team_Astana Pro Team</th>\n",
              "      <th>Team_Atum general / Tavira / Maria Nova Hotel</th>\n",
              "      <th>Team_Aviludo-Louletano</th>\n",
              "      <th>Team_B&amp;B Hotels - Vital Concept p/b KTM</th>\n",
              "      <th>Team_BEAT Cycling Club</th>\n",
              "      <th>Team_BHS - PL Beton Bornholm</th>\n",
              "      <th>Team_BORA - hansgrohe</th>\n",
              "      <th>Team_Bahrain - McLaren</th>\n",
              "      <th>Team_Bahrain Cycling Academy</th>\n",
              "      <th>...</th>\n",
              "      <th>Team_Rally Cycling</th>\n",
              "      <th>Team_Riwal Readynez Cycling Team</th>\n",
              "      <th>Team_SEG Racing Academy</th>\n",
              "      <th>Team_SSIOS Miogee Cycling Team</th>\n",
              "      <th>Team_Shenzhen Xidesheng Cycling Team</th>\n",
              "      <th>Team_Sport Vlaanderen - Baloise</th>\n",
              "      <th>Team_St George Continental Cycling Team</th>\n",
              "      <th>Team_St Michel - Auber93</th>\n",
              "      <th>Team_Swiss Racing Academy</th>\n",
              "      <th>Team_Tarteletto - Isorex</th>\n",
              "      <th>Team_Team Arkéa Samsic</th>\n",
              "      <th>Team_Team BridgeLane</th>\n",
              "      <th>Team_Team Bridgestone Cycling</th>\n",
              "      <th>Team_Team Felbermayr - Simplon Wels</th>\n",
              "      <th>Team_Team Hrinkow Advarics Cycleang</th>\n",
              "      <th>Team_Team INEOS</th>\n",
              "      <th>Team_Team Jumbo-Visma</th>\n",
              "      <th>Team_Team Medellin</th>\n",
              "      <th>Team_Team Novo Nordisk</th>\n",
              "      <th>Team_Team Sapura Cycling</th>\n",
              "      <th>Team_Team Skyline</th>\n",
              "      <th>Team_Team Sunweb</th>\n",
              "      <th>Team_Team Total Direct Energie</th>\n",
              "      <th>Team_Team UKYO</th>\n",
              "      <th>Team_Team Vorarlberg Santic</th>\n",
              "      <th>Team_Terengganu Inc. TSG Cycling Team</th>\n",
              "      <th>Team_Tianyoude Hotel Cycling Team</th>\n",
              "      <th>Team_Trek - Segafredo</th>\n",
              "      <th>Team_UAE-Team Emirates</th>\n",
              "      <th>Team_Uno-X Norwegian Development Team</th>\n",
              "      <th>Team_Utsunomiya Blitzen</th>\n",
              "      <th>Team_Vini Zabù - KTM</th>\n",
              "      <th>Team_Vino - Astana Motors</th>\n",
              "      <th>Team_VolkerWessels-Merckx</th>\n",
              "      <th>Team_Voster ATS Team</th>\n",
              "      <th>Team_W52 / FC Porto</th>\n",
              "      <th>Team_WSA KTM Graz</th>\n",
              "      <th>Team_Wibatech Merx 7R</th>\n",
              "      <th>Team_Work Service Dynatek Vega</th>\n",
              "      <th>Team_À BLOC CT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>Pim Ligthart</td>\n",
              "      <td>-0.022062</td>\n",
              "      <td>-0.373734</td>\n",
              "      <td>0.430120</td>\n",
              "      <td>-0.288801</td>\n",
              "      <td>0.406918</td>\n",
              "      <td>0.734329</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>-0.06004</td>\n",
              "      <td>-0.094836</td>\n",
              "      <td>-0.089671</td>\n",
              "      <td>-0.091799</td>\n",
              "      <td>-0.083741</td>\n",
              "      <td>-0.06004</td>\n",
              "      <td>-0.079012</td>\n",
              "      <td>-0.083741</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>-0.05459</td>\n",
              "      <td>-0.072645</td>\n",
              "      <td>-0.091799</td>\n",
              "      <td>-0.0764</td>\n",
              "      <td>-0.079012</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>Luka Mezgec</td>\n",
              "      <td>-0.326809</td>\n",
              "      <td>-0.407047</td>\n",
              "      <td>1.705693</td>\n",
              "      <td>-0.318085</td>\n",
              "      <td>0.307252</td>\n",
              "      <td>0.734329</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>-0.06004</td>\n",
              "      <td>-0.094836</td>\n",
              "      <td>-0.089671</td>\n",
              "      <td>-0.091799</td>\n",
              "      <td>-0.083741</td>\n",
              "      <td>-0.06004</td>\n",
              "      <td>-0.079012</td>\n",
              "      <td>-0.083741</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>-0.05459</td>\n",
              "      <td>-0.072645</td>\n",
              "      <td>-0.091799</td>\n",
              "      <td>-0.0764</td>\n",
              "      <td>-0.079012</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Dan Martin</td>\n",
              "      <td>3.990579</td>\n",
              "      <td>0.138986</td>\n",
              "      <td>-0.057217</td>\n",
              "      <td>4.960114</td>\n",
              "      <td>2.223250</td>\n",
              "      <td>1.204038</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>-0.06004</td>\n",
              "      <td>-0.094836</td>\n",
              "      <td>-0.089671</td>\n",
              "      <td>-0.091799</td>\n",
              "      <td>-0.083741</td>\n",
              "      <td>-0.06004</td>\n",
              "      <td>-0.079012</td>\n",
              "      <td>-0.083741</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>-0.05459</td>\n",
              "      <td>-0.072645</td>\n",
              "      <td>-0.091799</td>\n",
              "      <td>-0.0764</td>\n",
              "      <td>-0.079012</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Alberto Bettiol</td>\n",
              "      <td>-0.331989</td>\n",
              "      <td>-0.199931</td>\n",
              "      <td>-0.301228</td>\n",
              "      <td>-0.194738</td>\n",
              "      <td>0.481668</td>\n",
              "      <td>-0.439943</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>-0.06004</td>\n",
              "      <td>-0.094836</td>\n",
              "      <td>-0.089671</td>\n",
              "      <td>-0.091799</td>\n",
              "      <td>11.941524</td>\n",
              "      <td>-0.06004</td>\n",
              "      <td>-0.079012</td>\n",
              "      <td>-0.083741</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>-0.05459</td>\n",
              "      <td>-0.072645</td>\n",
              "      <td>-0.091799</td>\n",
              "      <td>-0.0764</td>\n",
              "      <td>-0.079012</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>Nathan Van Hooydonck</td>\n",
              "      <td>-0.444219</td>\n",
              "      <td>-0.155031</td>\n",
              "      <td>-0.501371</td>\n",
              "      <td>-0.450306</td>\n",
              "      <td>-0.488360</td>\n",
              "      <td>-0.909653</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>-0.06004</td>\n",
              "      <td>-0.094836</td>\n",
              "      <td>-0.089671</td>\n",
              "      <td>-0.091799</td>\n",
              "      <td>-0.083741</td>\n",
              "      <td>-0.06004</td>\n",
              "      <td>-0.079012</td>\n",
              "      <td>-0.083741</td>\n",
              "      <td>-0.079416</td>\n",
              "      <td>-0.05459</td>\n",
              "      <td>-0.072645</td>\n",
              "      <td>-0.091799</td>\n",
              "      <td>-0.0764</td>\n",
              "      <td>-0.079012</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 132 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Rider  ...  Team_À BLOC CT\n",
              "428          Pim Ligthart  ...               0\n",
              "137           Luka Mezgec  ...               0\n",
              "72             Dan Martin  ...               0\n",
              "77        Alberto Bettiol  ...               0\n",
              "512  Nathan Van Hooydonck  ...               0\n",
              "\n",
              "[5 rows x 132 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3qspSfrMwIY",
        "colab_type": "code",
        "outputId": "85cf6d37-fdc5-4680-a92f-84f64fb57875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# Drop rider name\n",
        "psg = psg.drop(['Rider'], axis=1)\n",
        "\n",
        "# rename so rest of coding works\n",
        "psg_prepared = psg\n",
        "\n",
        "# Load this for RMSE calcs\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Linear regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(psg_prepared, psg_labels)\n",
        "\n",
        "# Let's test more powerful model\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# Build decision tree model\n",
        "tree_reg = DecisionTreeRegressor()\n",
        "tree_reg.fit(psg_prepared, psg_labels)\n",
        "\n",
        "# we use 10 folds, which splits the data into 10 random folds\n",
        "# and evaluates the decision tree model 10 times\n",
        "# we test against a negative score cross-validation features expect\n",
        "# a utility function (greater is better) rather than a cost function\n",
        "# (where lower is better), this is the opposite of MSE\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(tree_reg, psg_prepared, psg_labels,\n",
        "                         scoring='neg_mean_squared_error', cv=10)\n",
        "tree_rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "# LEt's look at the results\n",
        "def display_scores(scores):\n",
        "  print('Scores:', scores)\n",
        "  print('Mean:', scores.mean())\n",
        "  print('Standard Deviation:', scores.std())\n",
        "\n",
        "display_scores(tree_rmse_scores)  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [0.         0.372678   0.         0.33333333 0.23570226 0.23570226\n",
            " 0.11785113 0.26352314 0.56916049 0.44405304]\n",
            "Mean: 0.25720036434718807\n",
            "Standard Deviation: 0.17437056253982827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi3Ex_WjyDUc",
        "colab_type": "code",
        "outputId": "0859a9ab-e8fc-49c7-acbd-79754cee91f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "# let's compute the scores for the linear regression to be sure\n",
        "lin_scores = cross_val_score(lin_reg, psg_prepared, psg_labels,\n",
        "                             scoring = 'neg_mean_squared_error', cv=10)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)\n",
        "# Woah, this is terrible after adding in the team dummy variables\n",
        "# will need unique data set if using LR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [1.24388453e+09 7.12254774e+07 3.16031423e+08 4.87153973e+08\n",
            " 1.82874838e+08 1.90755217e+10 1.04296014e+09 9.59344084e+10\n",
            " 2.61167117e+08 9.23662488e+07]\n",
            "Mean: 11870759385.990467\n",
            "Standard Deviation: 28567856799.1592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlqMyX0iyNG1",
        "colab_type": "code",
        "outputId": "321d9660-7220-4cb8-8dba-afe3bcd9d209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# Let's try a random forest model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "forest_reg = RandomForestRegressor()\n",
        "forest_reg.fit(psg_prepared, psg_labels)\n",
        "psg_predictions = forest_reg.predict(psg_prepared)\n",
        "forest_mse = mean_squared_error(psg_labels, psg_predictions)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        "forest_rmse\n",
        "scores = cross_val_score(forest_reg, psg_prepared, psg_labels,\n",
        "                         scoring='neg_mean_squared_error', cv=10)\n",
        "forest_rmse_scores = np.sqrt(-scores)\n",
        "display_scores(forest_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [0.14359472 0.20994047 0.01118034 0.20273135 0.08957461 0.22330224\n",
            " 0.14158331 0.29971051 0.34843918 0.37725472]\n",
            "Mean: 0.20473114454300578\n",
            "Standard Deviation: 0.10874821245577707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv994c0JzRFd",
        "colab_type": "code",
        "outputId": "e9d6a5bb-edfc-4917-f770-413d95536c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_distribs = {\n",
        "        'n_estimators': randint(low=75, high=100),\n",
        "        'max_features': randint(low=75, high=110),\n",
        "    }\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
        "                                n_iter=30, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
        "rnd_search.fit(psg_prepared, psg_labels)\n",
        "# grid search can take a while, this is a randomized approach"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=RandomForestRegressor(bootstrap=True,\n",
              "                                                   ccp_alpha=0.0,\n",
              "                                                   criterion='mse',\n",
              "                                                   max_depth=None,\n",
              "                                                   max_features='auto',\n",
              "                                                   max_leaf_nodes=None,\n",
              "                                                   max_samples=None,\n",
              "                                                   min_impurity_decrease=0.0,\n",
              "                                                   min_impurity_split=None,\n",
              "                                                   min_samples_leaf=1,\n",
              "                                                   min_samples_split=2,\n",
              "                                                   min_weight_fraction_leaf=0.0,\n",
              "                                                   n_estimators=100,\n",
              "                                                   n_jobs=None, oob_score=Fals...\n",
              "                                                   warm_start=False),\n",
              "                   iid='deprecated', n_iter=30, n_jobs=None,\n",
              "                   param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa057644eb8>,\n",
              "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa057644ef0>},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
              "                   verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkG5Z7Okzron",
        "colab_type": "code",
        "outputId": "0d1a2679-00ea-4542-9655-4f4742cdd2e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "cvres = rnd_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.23006142871589655 {'max_features': 103, 'n_estimators': 89}\n",
            "0.23240589684396382 {'max_features': 82, 'n_estimators': 95}\n",
            "0.23034173108009565 {'max_features': 93, 'n_estimators': 97}\n",
            "0.2321555292013315 {'max_features': 85, 'n_estimators': 85}\n",
            "0.23056398025745253 {'max_features': 98, 'n_estimators': 95}\n",
            "0.22743361328040157 {'max_features': 98, 'n_estimators': 77}\n",
            "0.23072815333122196 {'max_features': 96, 'n_estimators': 95}\n",
            "0.22822788414771839 {'max_features': 76, 'n_estimators': 98}\n",
            "0.23103767434402897 {'max_features': 104, 'n_estimators': 80}\n",
            "0.22742121225933332 {'max_features': 76, 'n_estimators': 95}\n",
            "0.2308947965002987 {'max_features': 107, 'n_estimators': 86}\n",
            "0.2300699570685919 {'max_features': 96, 'n_estimators': 86}\n",
            "0.2345732293808958 {'max_features': 99, 'n_estimators': 91}\n",
            "0.2322770146654577 {'max_features': 101, 'n_estimators': 84}\n",
            "0.23025922068209023 {'max_features': 102, 'n_estimators': 90}\n",
            "0.2291790684494485 {'max_features': 89, 'n_estimators': 89}\n",
            "0.22471921230529476 {'max_features': 77, 'n_estimators': 79}\n",
            "0.2284745101733227 {'max_features': 81, 'n_estimators': 95}\n",
            "0.23351728842189654 {'max_features': 83, 'n_estimators': 81}\n",
            "0.23060103375537122 {'max_features': 92, 'n_estimators': 78}\n",
            "0.23475538758448594 {'max_features': 99, 'n_estimators': 88}\n",
            "0.23305817138863485 {'max_features': 83, 'n_estimators': 95}\n",
            "0.22771800667097394 {'max_features': 76, 'n_estimators': 94}\n",
            "0.229953635719203 {'max_features': 102, 'n_estimators': 89}\n",
            "0.2293872236996248 {'max_features': 81, 'n_estimators': 86}\n",
            "0.2338921858864892 {'max_features': 82, 'n_estimators': 89}\n",
            "0.2332360919378524 {'max_features': 109, 'n_estimators': 88}\n",
            "0.22549061626655878 {'max_features': 91, 'n_estimators': 78}\n",
            "0.2264298581970507 {'max_features': 78, 'n_estimators': 76}\n",
            "0.2296275428461513 {'max_features': 80, 'n_estimators': 96}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JQTwzbT1VB_",
        "colab_type": "code",
        "outputId": "5f0f216c-34fb-4486-bbe4-71013fcdf097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# LEt's go back to the default\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "forest_reg = RandomForestRegressor()\n",
        "forest_reg.fit(psg_prepared, psg_labels)\n",
        "psg_predictions = forest_reg.predict(psg_prepared)\n",
        "forest_mse = mean_squared_error(psg_labels, psg_predictions)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        "forest_rmse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09219091248818344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGbzMCdhQJVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's look at the relative importance of each attribute\n",
        "feature_importances = forest_reg.feature_importances_\n",
        "feature_importances\n",
        "attributes = list(psg_prepared)\n",
        "sorted(zip(feature_importances, attributes), reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xNpdblU6GeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's evaluate the model on the test set\n",
        "final_model = forest_reg\n",
        "x_test = test_set.drop('Paris_Nice_etc', axis=1)\n",
        "y_test = test_set['Paris_Nice_etc'].copy()\n",
        "test_rider = test_set['Rider'].copy()\n",
        "\n",
        "########\n",
        "# Adjust the data\n",
        "# let's normalize the data\n",
        "x_test['GC'] = preprocessing.scale(x_test['GC'])\n",
        "x_test['Sprint'] = preprocessing.scale(x_test['Sprint'])\n",
        "x_test['TT'] = preprocessing.scale(x_test['TT'])\n",
        "x_test['Climber'] = preprocessing.scale(x_test['Climber'])\n",
        "x_test['Classic'] = preprocessing.scale(x_test['Classic'])\n",
        "x_test['Age'] = preprocessing.scale(x_test['Age'])\n",
        "x_test['Giro'] = preprocessing.scale(x_test['Giro'])\n",
        "x_test['Vuelta'] = preprocessing.scale(x_test['Vuelta'])\n",
        "x_test['Tour'] = preprocessing.scale(x_test['Tour'])\n",
        "x_test['Total'] = preprocessing.scale(x_test['Total'])\n",
        "x_test['san_remo_win'] = preprocessing.scale(x_test['san_remo_win'])\n",
        "x_test['lombardia_win'] = preprocessing.scale(x_test['lombardia_win'])\n",
        "x_test['flanders_win'] = preprocessing.scale(x_test['flanders_win'])\n",
        "x_test['lbl_win'] = preprocessing.scale(x_test['lbl_win'])\n",
        "x_test['roubaix_win'] = preprocessing.scale(x_test['roubaix_win'])\n",
        "x_test['strade_win'] = preprocessing.scale(x_test['strade_win'])\n",
        "#x_test['suisse_win'] = preprocessing.scale(x_test['suisse_win'])\n",
        "x_test['fleche_win'] = preprocessing.scale(x_test['fleche_win'])\n",
        "x_test['gent_win'] = preprocessing.scale(x_test['gent_win'])\n",
        "#x_test['Paris_Nice_etc'] = preprocessing.scale(x_test['Paris_Nice_etc'])\n",
        "x_test['e3_binckbank_win'] = preprocessing.scale(x_test['e3_binckbank_win'])\n",
        "x_test['amstel_win'] = preprocessing.scale(x_test['amstel_win'])\n",
        "#x_test['dauphine_win'] = preprocessing.scale(x_test['dauphine_win'])\n",
        "x_test['romandie_win'] = preprocessing.scale(x_test['romandie_win'])\n",
        "\n",
        "# Algorithims prefer working with numbers generally, so let's convert the team\n",
        "# proximity columns to numeric values\n",
        "x_test['Team'] = x_test['Team'].astype(str)\n",
        "\n",
        "# use pd.concat to join the new columns with your original dataframe\n",
        "x_test = pd.concat([x_test,pd.get_dummies(x_test['Team'], prefix='Team')],axis=1)\n",
        "\n",
        "# now drop the original 'country' column (you don't need it anymore)\n",
        "x_test.drop(['Team'],axis=1, inplace=True)\n",
        "\n",
        "# Drop rider name\n",
        "x_test = x_test.drop(['Rider'], axis=1)\n",
        "\n",
        "########\n",
        "\n",
        "x_test_prepared = x_test\n",
        "final_predictions = final_model.predict(x_test_prepared)\n",
        "\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}