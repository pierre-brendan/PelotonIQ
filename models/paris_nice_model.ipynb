{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paris_nice_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYbzlb+4QpFELXH9SJDsFv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pierre-brendan/PelotonIQ/blob/master/models/paris_nice_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBT1R8ObJoSU",
        "colab_type": "text"
      },
      "source": [
        "# First attempt at a model to predict the winner of Paris - Nice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSXKvTvZJjO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "1f507517-6ec0-4e48-df86-17a616b60da3"
      },
      "source": [
        "# Mount drive to get cyclist data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tZ6OqLLJysB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All this code is from the Kmeans clustering code\n",
        "\n",
        "# load modules\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# load the rider data\n",
        "cycling_data = pd.read_csv('/content/drive/My Drive/cycling_data/rider_data.csv')\n",
        "cycling_data = cycling_data[cycling_data['Rider'] != 'Bjorg Lambrecht ']\n",
        "cycling_data = cycling_data[cycling_data['Rider'] != 'Robbert de Greef ']\n",
        "\n",
        "# Load the GC data\n",
        "gc_winners = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/gc_winners_consolidated.csv')\n",
        "gc_winners.rename(columns = {'Cyclist':'Rider'}, inplace = True)\n",
        "\n",
        "# Merge the GC winners to the rider data set\n",
        "cycling_data = pd.merge(cycling_data, gc_winners, how='left', on='Rider')\n",
        "\n",
        "# Load in the Monuments data\n",
        "san_remo = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/san_remo.csv')\n",
        "san_remo = san_remo['san_remo_win'].groupby(san_remo['Rider']).sum()\n",
        "roubaix = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/roubaix.csv')\n",
        "roubaix = roubaix['roubaix_win'].groupby(roubaix['Rider']).sum()\n",
        "flanders = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/flanders.csv')\n",
        "flanders = flanders['flanders_win'].groupby(flanders['Rider']).sum()\n",
        "lombardia = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/lombardia.csv')\n",
        "lombardia = lombardia['lombardia_win'].groupby(lombardia['Rider']).sum()\n",
        "liege = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/liege.csv')\n",
        "liege = liege['lbl_win'].groupby(liege['Rider']).sum()\n",
        "strade = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/strade.csv')\n",
        "strade['strade_win'] = 1\n",
        "strade = strade['strade_win'].groupby(strade['Rider']).sum()\n",
        "suisse = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/suisse.csv')\n",
        "suisse['suisse_win'] = 1\n",
        "suisse = suisse['suisse_win'].groupby(suisse['Rider']).sum()\n",
        "romandie = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/romandie.csv')\n",
        "romandie['romandie_win'] = 1\n",
        "romandie = romandie['romandie_win'].groupby(romandie['Rider']).sum()\n",
        "paris_nice = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/paris_nice.csv')\n",
        "paris_nice['paris_nice_win'] = 1\n",
        "paris_nice = paris_nice['paris_nice_win'].groupby(paris_nice['Rider']).sum()\n",
        "gent = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/gent.csv')\n",
        "gent['gent_win'] = 1\n",
        "gent = gent['gent_win'].groupby(gent['Rider']).sum()\n",
        "fleche = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/fleche.csv')\n",
        "fleche['fleche_win'] = 1\n",
        "fleche = fleche['fleche_win'].groupby(fleche['Rider']).sum()\n",
        "e3_binckbank = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/e3_binckbank.csv')\n",
        "e3_binckbank['e3_binckbank_win'] = 1\n",
        "e3_binckbank = e3_binckbank['e3_binckbank_win'].groupby(e3_binckbank['Rider']).sum()\n",
        "dauphine = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/dauphine.csv')\n",
        "dauphine['dauphine_win'] = 1\n",
        "dauphine = dauphine['dauphine_win'].groupby(dauphine['Rider']).sum()\n",
        "amstel = pd.read_csv('/content/drive/My Drive/cycling_data/Historical_GC_Classics_Results/amstel.csv')\n",
        "amstel['amstel_win'] = 1\n",
        "amstel = amstel['amstel_win'].groupby(amstel['Rider']).sum()\n",
        "\n",
        "\n",
        "# Merge the Monuments winners to the rider data set\n",
        "cycling_data = pd.merge(cycling_data, san_remo, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, flanders, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, liege, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, lombardia, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, roubaix, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, strade, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, suisse, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, fleche, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, gent, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, paris_nice, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, e3_binckbank, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, amstel, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, dauphine, how='left', on='Rider')\n",
        "cycling_data = pd.merge(cycling_data, romandie, how='left', on='Rider')\n",
        "\n",
        "# Replace NaN with 0's\n",
        "cycling_data.fillna(0, inplace=True)\n",
        "\n",
        "# Drop country variable\n",
        "cycling_data = cycling_data.drop(['Country', 'crawl_date'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNIWRKzCKPUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cycling_data.describe()\n",
        "# Okay, let's make a column for winners of Paris-Nice type races\n",
        "# Currently I'm thinking Paris - Nice, Tour de Suisse and Dauphine (Tierrento is not in the data set currently)\n",
        "cycling_data['Paris_Nice_etc'] = cycling_data['paris_nice_win'] + cycling_data['dauphine_win'] + cycling_data['suisse_win']\n",
        "\n",
        "# Will need to drop those 3 columns now\n",
        "cycling_data = cycling_data.drop(['paris_nice_win', 'dauphine_win', 'suisse_win'], axis = 1)\n",
        "\n",
        "# Split the data sets\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set = train_test_split(cycling_data, test_size = 0.2, \n",
        "                                       random_state = 42)\n",
        "# first let's make a fresh copy of our data and drop what we are trying\n",
        "# to predict so it doesn't have any transmations applied to it\n",
        "psg = train_set.drop('Paris_Nice_etc', axis=1)\n",
        "psg_labels = train_set['Paris_Nice_etc'].copy()\n",
        "\n",
        "\n",
        "# Algorithims prefer working with numbers generally, so let's convert the team\n",
        "# proximity columns to numeric values\n",
        "psg['Team'] = psg['Team'].astype(str)\n",
        "housing_cat = psg[['Team']]\n",
        "# Problem is if we use numeric examples for these variables algorithims\n",
        "# will think they are near eachother. Instead we should make some one-hot\n",
        "# encodings otherwise known as dummy variables for each category as it's own\n",
        "# column\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "cat_encoder = OrdinalEncoder()\n",
        "psg_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "cat_attribs = ['Team']\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "      ('cat', OneHotEncoder(), cat_attribs),\n",
        "])\n",
        "\n",
        "psg_prepared = full_pipeline.fit_transform(psg) # applying this to pandas dataframe called housing\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwOaWj0tP9qV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "ae8bb7a8-f4b8-409e-ec0d-9bc617bb5524"
      },
      "source": [
        "#pd.DataFrame(psg_prepared)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(0, 18)\\t1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(0, 21)\\t1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(0, 3)\\t1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(0, 59)\\t1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(0, 28)\\t1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>(0, 33)\\t1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>(0, 34)\\t1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>635</th>\n",
              "      <td>(0, 26)\\t1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>636</th>\n",
              "      <td>(0, 92)\\t1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>637</th>\n",
              "      <td>(0, 89)\\t1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>638 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "0      (0, 18)\\t1.0\n",
              "1      (0, 21)\\t1.0\n",
              "2       (0, 3)\\t1.0\n",
              "3      (0, 59)\\t1.0\n",
              "4      (0, 28)\\t1.0\n",
              "..              ...\n",
              "633    (0, 33)\\t1.0\n",
              "634    (0, 34)\\t1.0\n",
              "635    (0, 26)\\t1.0\n",
              "636    (0, 92)\\t1.0\n",
              "637    (0, 89)\\t1.0\n",
              "\n",
              "[638 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOcvD8lLKL4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Also from KMeans code\n",
        "# This would be the best approach to removing special characters\n",
        "#dictionary = {'ž':'z', 'č':'c', 'ü':'u', 'á':'a', 'é':'e', 'ö':'o', 'ó':'o', 'ç':'c',\n",
        "#              'ń':'ń', 'í':'i', 'è':'e'}\n",
        "#cycling_data.replace(dictionary, regex=True, inplace=True)\n",
        "\n",
        "# make a df without cyclist name in it for clustering\n",
        "d = psg.drop(['Rider', 'Team'], axis=1)\n",
        "\n",
        "# let's normalize the data\n",
        "d['GC'] = preprocessing.scale(d['GC'])\n",
        "d['Sprint'] = preprocessing.scale(d['Sprint'])\n",
        "d['TT'] = preprocessing.scale(d['TT'])\n",
        "d['Climber'] = preprocessing.scale(d['Climber'])\n",
        "d['Classic'] = preprocessing.scale(d['Classic'])\n",
        "d['Age'] = preprocessing.scale(d['Age'])\n",
        "d['Giro'] = preprocessing.scale(d['Giro'])\n",
        "d['Vuelta'] = preprocessing.scale(d['Vuelta'])\n",
        "d['Tour'] = preprocessing.scale(d['Tour'])\n",
        "d['Total'] = preprocessing.scale(d['Total'])\n",
        "d['san_remo_win'] = preprocessing.scale(d['san_remo_win'])\n",
        "d['lombardia_win'] = preprocessing.scale(d['lombardia_win'])\n",
        "d['flanders_win'] = preprocessing.scale(d['flanders_win'])\n",
        "d['lbl_win'] = preprocessing.scale(d['lbl_win'])\n",
        "d['roubaix_win'] = preprocessing.scale(d['roubaix_win'])\n",
        "d['strade_win'] = preprocessing.scale(d['strade_win'])\n",
        "#d['suisse_win'] = preprocessing.scale(d['suisse_win'])\n",
        "d['fleche_win'] = preprocessing.scale(d['fleche_win'])\n",
        "d['gent_win'] = preprocessing.scale(d['gent_win'])\n",
        "#d['Paris_Nice_etc'] = preprocessing.scale(d['Paris_Nice_etc'])\n",
        "d['e3_binckbank_win'] = preprocessing.scale(d['e3_binckbank_win'])\n",
        "d['amstel_win'] = preprocessing.scale(d['amstel_win'])\n",
        "#d['dauphine_win'] = preprocessing.scale(d['dauphine_win'])\n",
        "d['romandie_win'] = preprocessing.scale(d['romandie_win'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3qspSfrMwIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}